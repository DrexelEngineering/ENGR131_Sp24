{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# ⌛️ Practice Final Exam\n",
    "\n",
    "This Practice Final Exam is designed to test your mastery of the Python programming language. You will be asked to respond to a series of programming problems.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "You are allowed to use anything with the python kernel to help you solve the problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Question 1:  Probability of Common Birthdays\n",
    "\n",
    "Given a group of N people, what is the probability that at least one day of the year is the birthday of two or more members of the group? In this assignment, we will use simulations of groups of people with randomly assigned birthdays to find out.\n",
    "\n",
    "\n",
    "\n",
    "The program template given below, my_birthday.py, defines the function do_birthday_simulation() which has three arguments. N is the number of people, M is the number of simulation trials to perform, and a_seed is the seed for the pseudorandom number generator. Note that the statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "birthdays = [random.randint(1,365) for j in range(N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assigns a random integer between 1 and 365 inclusive to each of N elements of a list called birthdays. Complete the function definition so that it returns True if at least one of those integers appears two or more times in the list.\n",
    "\n",
    "The __main__ block is provided in the template so that you can run your program locally on your own computer for testing. It does not matter what the __main__ block contains when you submit; you will only be graded on the performance of your do_birthday_simulation() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "D R E X E L   U N I V E R S I T Y\n",
    "ENGR 131 -- Introductory Programming for Engineers\n",
    "\n",
    "Programming Assignment 1\n",
    "\n",
    "Written by Your Name Here\n",
    "Term:  Winter 2020-2021\n",
    "'''\n",
    "import random\n",
    "def do_birthday_simulation (N, M, a_seed):\n",
    "    random.seed(a_seed)\n",
    "    num_hits = 0\n",
    "    ''' run M simulations and increment num_hits for each one that is a hit '''\n",
    "    for i in range(M):\n",
    "        ''' This statement generates the N random birthdays '''\n",
    "        birthdays = [random.randint(1,365) for j in range(N)]\n",
    "        ''' Your code goes here '''\n",
    "    return num_hits / M\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    N = 25\n",
    "    M = 100\n",
    "    a_seed = 1972227\n",
    "    print('For {:d} simulations of groups of {:d} people with seed {:d},\\nthe probability of a common birthday is {:.2f}'.format(N,M,a_seed,do_birthday_simulation(N,M,a_seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2: Manipulating DNA\n",
    "\n",
    "Part A:\n",
    "Given: A DNA string, s, where the alphabet of DNA is from the set {'A','C','G','T'}\n",
    "\n",
    "Return: Four integers (separated by spaces) counting the respective number of times that the symbols 'A', 'C', 'G', and 'T' occur in s. On the next line, a float with the CG% (which is the combined percentages of Cs and Gs in the string). The percentage is from 0 to 100 and NOT a fractional percentage.\n",
    "\n",
    "Sample Input: ATTTTAAGGAGTTTAAAATGGATAAGAAGCAAGTAACGGATTTAAGGTCGGAACTACTCGATTCACGTTT\n",
    "\n",
    "Sample Output: 25 8 16 21\n",
    "\n",
    "34.3\n",
    "\n",
    "Part B:\n",
    "Given two strings s and t of equal length, the Hamming distance between s and t, denoted\n",
    ", is the number of corresponding symbols that differ in s and t.\n",
    "\n",
    "Given: Two DNA strings s and t of equal length .\n",
    "\n",
    "Return: The Hamming distance $d_H(s,t)$.\n",
    "\n",
    "1st Sample Input:\n",
    "\n",
    "GATATCGTCTGGGACCT\n",
    "\n",
    "CATCGCATTTACGGCCT\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "8\n",
    "\n",
    "\n",
    "\n",
    "2nd Sample Input:\n",
    "\n",
    "GATATCGTCTGGGACCT\n",
    "\n",
    "CCATCGCATTTACGGCCT\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "Error: Sequences Length Mismatch\n",
    "\n",
    "\n",
    "\n",
    "You need to write a function for each part.\n",
    "The declarations for both functions are given in the template.\n",
    "\n",
    "You may use more functions if you find that helpful for your implementation, but only these two will be explicitly checked.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "slist=input()\n",
    "seq=list(slist)\n",
    "\n",
    "def countBases(seq):\n",
    "    # return count of As, count of Cs, count of Gs, count of Ts, and Percentage of Cs and Gs combined\n",
    "    \n",
    "    return '{:d} {:d} {:d} {:d}\\n{:2.1f}'.format(A, C, G, T, cg_percentage)\n",
    "    #return A, C, T, G, cg_percentage\n",
    "\n",
    "def hammingdistance(seq_a, seq_b):\n",
    "    #return the number of differences between the two sequences\n",
    "    #If the sequences are not the same length, return \"Error: Sequences Length Mismatch\"\n",
    "                \n",
    "    return hamming_distance\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # optional - add any test code here inside this block. we do this so that when the zyBooks tests includes \n",
    "    # your files to call your functions directly that the testing code in this block is not invoked\n",
    "    \n",
    "    #basecount=countBases(<input sequence here>)\n",
    "   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Password modifier\n",
    "\n",
    "Many user-created passwords are simple and easy to guess. Write a program that takes a simple password and makes it stronger by replacing characters using the key below, and by appending \"!\" to the end of the input string.\n",
    "\n",
    "i becomes 1\n",
    "a becomes @\n",
    "m becomes M\n",
    "B becomes 8\n",
    "s becomes $\n",
    "\n",
    "Ex: If the input is:<br>\n",
    "```mypassword```<br>\n",
    "the output is:<br>\n",
    "```Myp@$$word!```<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "word = input()\n",
    "password = ''\n",
    "\n",
    "''' Type your code here. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Parsing dates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to read dates from input, one date per line. Each date's format must be as follows: March 1, 1990. Any date not following that format is incorrect and should be ignored. The input ends with -1 on a line alone. Output each correct date as: 3/1/1990.\n",
    "\n",
    "Hint: Use string[start:end] to get a substring when parsing the string and extracting the date. Use the split() method to break the input into tokens.\n",
    "\n",
    "Ex: If the input is:\n",
    "```March 1, 1990```<br>\n",
    "```April 2 1995```<br>\n",
    "```7/15/20```<br>\n",
    "```December 13, 2003```<br>\n",
    "```-1```<br>\n",
    "then the output is:<br>\n",
    "```3/1/1990```<br>\n",
    "```12/13/2003```<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def get_month_as_int(monthString):\n",
    "\n",
    "    if monthString == 'January':\n",
    "        month_int = 1\n",
    "    elif monthString == 'February':\n",
    "        month_int = 2\n",
    "    elif monthString == 'March':\n",
    "        month_int = 3\n",
    "    elif monthString == 'April':\n",
    "        month_int = 4\n",
    "    elif monthString == 'May':\n",
    "        month_int = 5\n",
    "    elif monthString == 'June':\n",
    "        month_int = 6\n",
    "    elif monthString == 'July':\n",
    "        month_int = 7\n",
    "    elif monthString == 'August':\n",
    "        month_int = 8\n",
    "    elif monthString == 'September':\n",
    "        month_int = 9\n",
    "    elif monthString == 'October':\n",
    "        month_int = 10\n",
    "    elif monthString == 'November':\n",
    "        month_int = 11\n",
    "    elif monthString == 'December':\n",
    "        month_int = 12\n",
    "    else:\n",
    "        month_int = 0\n",
    "\n",
    "    return month_int\n",
    "\n",
    "\n",
    "user_string = input()\n",
    "\n",
    "# TODO: Read dates from input, parse the dates to find the one\n",
    "#       in the correct format, and output in m/d/yyyy format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## For loops over parallel containers with zip()\n",
    "In chemistry, equilibrium constants can be expressed as products of species concentrations each raised to a power corresponding to that species' stoichiometric coefficient in chemical reaction. For example, for the reaction\n",
    "\n",
    "$$ A + 3B \\rightleftharpoons 2C $$\n",
    "\n",
    "the equilibrium constant is\n",
    "\n",
    "$$ K = \\frac{[C]^2}{[A][B]^3} $$\n",
    "\n",
    "where [ ] indicate species concentration.  Note that stoichiometric coefficients of reactants (species on the left-hand side of the arrows) are negative, and stoichiometric coefficients of products (species on the right-hand side of the arrows) are positive.  That is, we could also write the equilibrium constant for this reaction as\n",
    "\n",
    "$$ K = [A]^{-1}[B]^{-3}[C]^2 $$\n",
    "\n",
    "Generally, for a set of species \n",
    "\n",
    "$$ I \\in (A, B, C, \\dots ) $$\n",
    "\n",
    "and their corresponding stoichiometric coefficents:\n",
    "\n",
    "$$ \\nu _i \\in ( \\nu _A, \\nu _B, \\nu _C, \\dots ) $$\n",
    "\n",
    "we can express the equilibrium constant as a **product** expansion over N species in the reaction:\n",
    "\n",
    "$$ K = \\prod _{i=1}^{N} [I]^{\\nu _i} = [A]^{\\nu _A} [B]^{\\nu _B} [C]^{\\nu _C}\\dots $$\n",
    "\n",
    "In this lab, you will write a program to compute the value of K given two lists:  the first is a list of values of concentrations of species, and the second is the corresponding list of stoichiometric coefficients.  Each list is input as a comma-separated string, and the two lists are input on separate lines.  For example, if the input is\n",
    "\n",
    "```\n",
    "0.5,0.75,1.3,0.8\n",
    "-1,-2,2,1\n",
    "```\n",
    "\n",
    "the program will compute (0.5)<sup>-1</sup>(0.75)<sup>-2</sup>(1.3)<sup>2</sup>(0.8)<sup>1</sup>, generating the single output\n",
    "\n",
    "```\n",
    "4.80711\n",
    "```\n",
    "\n",
    "A key aspect of this lab is that the program should be able to handle **any** number of species; this is only determined by the number of comma-separated elements in the input list.\n",
    "\n",
    "Python provides the `zip()` built-in class to permit iteration over multiple containers in parallel.  When provided multiple containers, `zip()` yields tuples of container elements one at a time, like this:\n",
    "\n",
    "```\n",
    ">>> a=[1,2,3]\n",
    ">>> b=['c','d','e']\n",
    ">>> zip(a,b)\n",
    "<zip object at 0x00000245990F84C0>\n",
    ">>> list(zip(a,b))\n",
    "[(1, 'c'), (2, 'd'), (3, 'e')]\n",
    "```\n",
    "\n",
    "Because a `zip` is iterable, you need not cast it to a `list` to iterate over it:\n",
    "```\n",
    ">>> for i,j in zip(a,b):\n",
    "...     print(i,j)\n",
    "... \n",
    "1 c \n",
    "2 d \n",
    "3 e \n",
    "```\n",
    "\n",
    "Use a `for` loop over a `zip` of the two input lists to compute a value for K.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "C = list(map(float,input().split(',')))\n",
    "nu = list(map(float,input().split(',')))\n",
    "\n",
    "# Your code goes here; assign a value to K, the equilibrium constant\n",
    "\n",
    "print(f'{K:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q5 - Making a Graph": {
     "name": "q5 - Making a Graph",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> points_ = [3, 3, 3, 6, 14, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q5_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_1'\n>>> max_score = 3\n>>> score = 0\n>>> if np.__version__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': np.__version__}\n>>> responder.add_response(response)\n>>> assert np.__version__ is not None, 'numpy is incorrectly imported'\n",
         "failure_message": "numpy incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "numpy correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_2'\n>>> max_score = 3\n>>> score = 0\n>>> if plt.__package__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': plt.__package__}\n>>> responder.add_response(response)\n>>> assert plt.__package__ is not None, 'plt is incorrectly imported'\n",
         "failure_message": "plt random incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "plt correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> from ENGR131_Util_2024 import responses\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_3'\n>>> max_score = 3\n>>> score = 0\n>>> if callable(draw_card_eq):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': callable(draw_card_eq)}\n>>> responder.add_response(response)\n>>> assert callable(draw_card_eq), 'draw_card_eq is not a function'\n",
         "failure_message": "draw_card_eq is not a function",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "draw_card_eq is callable."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import matplotlib.pyplot as plts\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_4'\n>>> max_score = 6\n>>> score = 0\n>>> if isinstance(plot_[0], plts.Line2D):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': isinstance(plot_[0], plts.Line2D)}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> scorer = submit_score()\n>>> assert isinstance(plot_[0], plts.Line2D), 'You did not return a plot object.'\n",
         "failure_message": "You did not return a plot object.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "You successfully returned a plot object."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_5'\n>>> max_score = 14\n>>> score = 0\n>>> if np.isclose(sum(plot_[0].get_xdata()[::3]), 1.6561871562318847e-07):\n...     score += int(max_score / 2)\n>>> if np.isclose(sum(plot_[0].get_ydata()[::4]), 1.2500506348082654):\n...     score += int(max_score / 2)\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': sum(plot_[0].get_xdata()[::3])}\n>>> responder.add_response(response)\n>>> assert np.isclose(sum(plot_[0].get_xdata()[::3]), 1.6561871562318847e-07), 'The values for x_data in the plot are incorrect. '\n>>> assert np.isclose(sum(plot_[0].get_ydata()[::4]), 1.2500506348082654), 'The values for y_data in the plot are incorrect. '\n",
         "failure_message": "The values for your plot are incorrect.",
         "hidden": false,
         "locked": false,
         "points": 14,
         "success_message": "The values for your plot are correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q5_6'\n>>> max_score = 6\n>>> score = 0\n>>> if plot_[0].get_color() == 'red' or plot_[0].get_color() == (1.0, 0.0, 0.0, 1.0) or plot_[0].get_color() == 'r':\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': plot_[0].get_color()}\n>>> responder.add_response(response)\n>>> assert plot_[0].get_color() == 'red' or plot_[0].get_color() == (1.0, 0.0, 0.0, 1.0) or plot_[0].get_color() == 'r', 'The line on the plot is not the correct color'\n",
         "failure_message": "The plot is not red.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "The plot is red as expected."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6 - Exploring DataTypes": {
     "name": "q6 - Exploring DataTypes",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> points_ = [3, 3, 3, 3, 6, 6, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q6_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_1'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDQ71dNmKvaPlZOj3cLT2FVfh66b09i0yV2Fl08bcFY0K_Io7ju7utXkX3cCmsb9HMsHTAHERX0X48acRp1MGHYXxSg==')\n>>> if str(int_) == out and isinstance(int_, int):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': int_}\n>>> responder.add_response(response)\n>>> assert isinstance(int_, int)\n>>> assert str(int_) == out, 'int_ incorrectly implemented.'\n",
         "failure_message": "int_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "int_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_2'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRABl3uUfW0G0yLb5kCpVpz5XBRYUjowgJ9_c9CNAGielysMhb5cp72zDF0Gi9abZrATkUoZfUGv7UJp65Cm7WvjiQ==')\n>>> if str(float_) == out and isinstance(float_, float):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': float_}\n>>> responder.add_response(response)\n>>> assert isinstance(float_, float)\n>>> assert str(float_) == out, 'float_ incorrectly implemented.'\n",
         "failure_message": "float_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "float_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_3'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRDR42csyMOkhel0VkaN7JXse5_3OFTam1ryIyiJvEdIcfDCfocojIiGZU2PPJQm-rrfBNXLyzMQ-QJgmZi7qEdthA==')\n>>> if str(bool_) == out and isinstance(bool_, bool):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': bool_}\n>>> responder.add_response(response)\n>>> assert isinstance(bool_, bool)\n>>> assert str(bool_) == out, 'bool_ incorrectly implemented.'\n",
         "failure_message": "bool_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "bool_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_4'\n>>> max_score = 3\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRECpI3kPdhirMzwLAddFoJKDXs7mXJ5AWPYJTx_gTKGYY9VR0REjaPKLCAc0MQ5UuSr4cMcBBc8zSVg2GT6LiDvLg==')\n>>> if str(string_) == out and isinstance(string_, str):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(string_)}\n>>> responder.add_response(response)\n>>> assert isinstance(string_, str)\n>>> assert str(string_) == out, 'string_ incorrectly implemented.'\n",
         "failure_message": "string_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "string_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_5'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRFLoBpFP_06PNjYcIdyOpLGFYYboKIjMjTAu936eLjoKByeaF5XTyYcvGh5PWyVVU1kFUqWj4YeqbRDfMTRpPYXGw==')\n>>> if str(list_) == out and isinstance(list_, list):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(list_)}\n>>> responder.add_response(response)\n>>> assert isinstance(list_, list)\n>>> assert str(list_) == out, 'list_ incorrectly implemented.'\n",
         "failure_message": "list_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "list_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_6'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRGEX2Cl-qHsEg1NFnwyZSHVLsjlc1JJWn4Lj76LT7dsEoNqlBpXQry0zKyFS2oCSzdJbYSm95SKxB96pM_HHsyuNw==')\n>>> if str(tuple_) == out and isinstance(tuple_, tuple):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(tuple_)}\n>>> responder.add_response(response)\n>>> assert isinstance(tuple_, tuple)\n>>> assert str(tuple_) == out, 'tuple_ incorrectly implemented.'\n",
         "failure_message": "tuple_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "tuple_ correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q6_7'\n>>> max_score = 6\n>>> score = 0\n>>> out = get_string_from_encrypted_string(b'gAAAAABkDRG1TzclExNe_t7qeJgaHYC9uWufJOfW5u7L198U2jtPxlFPQTnL9qj0MFHrNC7pIUfpz7od9FbuyQy6nuNnEFvlk2ZWGw3xRiU_wh4fVtRuV-Y=')\n>>> if str(dict_) == out and isinstance(dict_, dict):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(dict_)}\n>>> responder.add_response(response)\n>>> assert isinstance(dict_, dict)\n>>> assert str(dict_) == out, 'dict_ incorrectly implemented.'\n",
         "failure_message": "dict_ incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "dict_ correctly implemented."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7-Building a Thermometer": {
     "name": "q7-Building a Thermometer",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> points_ = [6, 6, 8, 8, 8]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q7_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q7_1'\n>>> max_score = 6\n>>> score = 0\n>>> if isinstance(Thermometer, type):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(isinstance(Thermometer, type))}\n>>> responder.add_response(response)\n>>> assert isinstance(Thermometer, type), 'The Class Thermometer is not implemented.'\n",
         "failure_message": "The Class Thermometer is not implemented.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "The Class Thermometer is implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q7_2'\n>>> max_score = 6\n>>> score = 0\n>>> t = Thermometer(25)\n>>> if hasattr(t, 'temperature_c') and t.temperature_c == 25:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(t.temperature_c)}\n>>> responder.add_response(response)\n>>> assert hasattr(t, 'temperature_c'), \"Thermometer does not have 'temperature' attribute\"\n>>> assert t.temperature_c == 25, 'Thermometer initialization did not set attribute temperature correctly'\n",
         "failure_message": "The Class Thermometer initialization is implemented incorrectly.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "The Class Thermometer initialization is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q7_3'\n>>> max_score = 8\n>>> score = 0\n>>> t = Thermometer(25)\n>>> t.set_temperature(50)\n>>> if t.temperature_c == 50.0:\n...     score += 4\n>>> t_ = Thermometer(25)\n>>> t_.set_temperature('abc')\n>>> out = str(t_.temperature_c)\n>>> if out == 'fail':\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([t.temperature_c, t_.temperature_c])}\n>>> responder.add_response(response)\n>>> t = Thermometer(25)\n>>> t.set_temperature(50)\n>>> assert t.temperature_c == 50.0, 'set temperature does not function properly'\n>>> t = Thermometer(25)\n>>> t.set_temperature('abc')\n>>> out = str(t.temperature_c)\n>>> assert out == 'fail', 'set temperature does not return the correct response when a unsuitable input is provided'\n",
         "failure_message": "set_temperature can not correctly handle non numeric inputs.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "set_temperature can correctly handle non numeric inputs."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q7_4'\n>>> max_score = 8\n>>> score = 0\n>>> t = Thermometer(0)\n>>> if t.to_fahrenheit() == 32.0:\n...     score += 4\n>>> hold = t.to_fahrenheit()\n>>> t.set_temperature(20)\n>>> if t.to_fahrenheit() == 68.0:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([hold, t.to_fahrenheit()])}\n>>> responder.add_response(response)\n>>> t = Thermometer(0)\n>>> assert t.to_fahrenheit() == 32.0, 'Incorrect conversion to Fahrenheit.'\n>>> t.set_temperature(20)\n>>> assert t.to_fahrenheit() == 68.0, 'Incorrect conversion to Fahrenheit.'\n",
         "failure_message": "Incorrect conversion to Fahrenheit.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "Correct conversion to Fahrenheit."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q7_5'\n>>> max_score = 8\n>>> score = 0\n>>> conditions = [hasattr(water_sensor, 'temperature_c'), hasattr(water_sensor, 'to_fahrenheit'), temp_c == 12, temp_f == 53.6]\n>>> statements = [\"Thermometer does not have 'temperature' attribute\", \"Thermometer does not have 'to_fahrenheit' attribute\", 'Incorrect temperature for temp_c.', 'Incorrect temperature for temp_f.']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "Incorrect conversion to Fahrenheit.",
         "hidden": false,
         "locked": false,
         "points": 8,
         "success_message": "Correct conversion to Fahrenheit."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8-Determining a Price for a Circuit": {
     "name": "q8-Determining a Price for a Circuit",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> points_ = [0, 1, 0, 6, 15, 12, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q8_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_1'\n>>> max_score = 0\n>>> score = 0\n>>> conditions = [parts_cost['10-ohm resistor'] == 0.025, parts_cost['100-ohm resistor'] == 0.03, parts_cost['1-pF capacitor'] == 0.05, parts_cost['10-pF capacitor'] == 0.12]\n>>> statements = ['10-ohm resistor not correctly defined', '100-ohm resistor not correctly defined', '1-pF capacitor not correctly defined', '10-pF capacitor not correctly defined']\n>>> for condition in conditions:\n...     if condition:\n...         score += 0\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "parts_cost is incorrect. Please make sure you did not modify the dictionary.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "parts_cost is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_2'\n>>> max_score = 1\n>>> score = 0\n>>> if np.__version__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(np.__version__)}\n>>> responder.add_response(response)\n>>> assert np.__version__ is not None, 'numpy is incorrectly imported'\n",
         "failure_message": "numpy incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "numpy correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_3'\n>>> max_score = 0\n>>> score = 0\n>>> conditions = [circuit_parts['10-ohm resistor']['quantity'] == 10, circuit_parts['10-pF capacitor']['quantity'] == 3, circuit_parts['1-pF capacitor']['quantity'] == 7, circuit_parts['Custom Processor']['quantity'] == 2, circuit_parts['Custom Processor']['price'] == 12]\n>>> statements = ['10-ohm resistor quantity not correctly defined', '10-pF capacitor quantity not correctly defined', '1-pF capacitor quantity not correctly defined', 'Custom Processor quantity not correctly defined', 'Custom Processor price not correctly defined']\n>>> for condition in conditions:\n...     if condition:\n...         score += 0\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "circuit_parts is incorrect. Please make sure you did not modify the dictionary.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "circuit_parts is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_4'\n>>> max_score = 6\n>>> score = 0\n>>> conditions = [price_calculator.__name__ == 'price_calculator', price_calculator.__code__.co_argcount == 3]\n>>> statements = ['you did not name price_calculator correctly', 'price calculator does not have the correct number of inputs']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([price_calculator.__name__, price_calculator.__code__.co_argcount])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "price_calculator call is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "price_calculator call is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_5'\n>>> max_score = 15\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkDz6Y_aio_akqMGkihfI5zKR2KkUg0yXVVHNrVV82qunlAwRjVZN2R2OYzUqkBBLBG-qd4t_2Vpx-iHxYPLMGTYQsFA==')\n...     if str(price_calculator(parts_cost, circuit_parts, 0.2)) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(out)}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert str(price_calculator(parts_cost, circuit_parts, 0.2)) == out, 'price_calculator  computation is incorrect.'\n",
         "failure_message": "price_calculator computation is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 15,
         "success_message": "price_calculator computation is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_6'\n>>> max_score = 12\n>>> score = 0\n>>> parts_2 = parts_cost.copy()\n>>> parts_2['10-ohm resistor'] = 10\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD3dtfMyEiX9AYR1pum4OZ5xSbbZ367hae3wxg5SSAcor4m5CXO6u1OthJkNgyGQUotRmCY2v18f4rjxK7Z3kbCNC3A==')\n...     if out == str(price_calculator(parts_2, circuit_parts, 0.2)):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(out)}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert out == str(price_calculator(parts_2, circuit_parts, 0.2)), 'Your code does not use the parts_cost correctly'\n",
         "failure_message": "Your code does not use the parts_cost correctly.",
         "hidden": false,
         "locked": false,
         "points": 12,
         "success_message": "Your code correctly uses the parts_cost."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q8_7'\n>>> max_score = 6\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD3D3Z-O5XJGgN67FRSetS5oiOetUTzWxQFbw_OTKnrjBEhnelTKcH0d22z4AneFL8pYrtOgSg0Q2qYc0A4dI-VdzzcV6pXrv5aKw-FAVmhHMZ7U=')\n...     if print_total(price_calculator(parts_cost, circuit_parts, profit)) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(out)}\n>>> responder.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     assert print_total(price_calculator(parts_cost, circuit_parts, profit)) == out, 'The string being printed is not correct'\n",
         "failure_message": "print message is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "print message is correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9-Plotting and Fitting": {
     "name": "q9-Plotting and Fitting",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> points_ = [3, 9, 4, 6, 3, 9, 3, 4, 4, 3, 3, 6, 6]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q9_{i + 1}')\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_1'\n>>> max_score = 3\n>>> score = 0\n>>> conditions = [np.__name__ == 'numpy', plt.__name__ == 'matplotlib.pyplot', 'curve_fit' in dir()]\n>>> statements = ['numpy not imported correctly', 'matplotlib.pyplot not imported correctly', 'scipy.optimize.curve_fit not imported correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(plt.__name__)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "Your input statements are incorrect.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Your input statements are correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_2'\n>>> max_score = 9\n>>> score = 0\n>>> x_test = np.array([0, 1, 2])\n>>> (a_test, b_test, c_test) = (1, 1, 1)\n>>> expected_output = np.array([0.60653066, 1.0, 0.60653066])\n>>> conditions = [np.allclose(gaussian(x_test, a_test, b_test, c_test), expected_output)]\n>>> statements = ['gaussian function is not implemented correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 9\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([*gaussian(x_test, a_test, b_test, c_test)])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "gaussian function is not implemented correctly",
         "hidden": false,
         "locked": false,
         "points": 9,
         "success_message": "gaussian function is implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_3'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [np.allclose(x_data[0], -20), np.allclose(x_data[-1], 20), len(x_data) == 100, np.isclose(sum(x_data[3::3]), 19.99999999999997)]\n>>> statements = ['x_data is not defined correctly', 'x_data is not defined correctly', 'x_data length is not correct', 'x_data is not defined correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "x_data is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "x_data is defined correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_4'\n>>> max_score = 6\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD-NzYrMglFaqNyS-zlkoQo-gwxc1YCD39uP-uNVNborNwKBB7YKbPEpayy9rq7hUGxJhZWrWmXBDQ14fxazkpMi5v-8ArClYcJqu2ZJvUs2LKzPwphZZ63pfZBxs8IK0DIw-EnU5mRoiaMT3YoTAD7rSGUrnDdqM44YGV3b_Gyt7mYE0n_obgjbXngI0DbuJzExiXeA4KQNpSsKJD6x870owlz7wNXADMhSrU03suFLlUx1pgGwJsg-7lQhUocs64ZahOJvSfABgqu_Ml_SDkaudvTyHTFCPy-bnq3xn-Cc4d9jmsdOxUmqMvl3xLZw1ALt6YrMBdlNZh0hBgjrT4iVP9tySJBG8dnov7TLz9_PuWRGRulKG-tYZU9XJ8uuFC09mXpDLE49gdlCDp_jYbvYfWX6rPlgBd7pXyQ2YWAKajlRzuJ1Q7TrXSVm_Xbj2eF48_iehGgz2cuzg0YARRKXvrg3JFdRn-jRhN9Pop4SoJVEcIbh6p6AmU0u2rUTFDN5UazGdLSWav8g2xQyHCm8_2i9il6lVF3_H4E5gdycNi6eb4hUV0i7XY1rUzfulJYmJzWzQk3KgbR54In9AfLWvgHY0IcBduStXBmpMfwIG7NMbbSPhElQ0D6gXjA3F7zpkahXZ3S0ihF0bfHvY32pIfRVORtMT811bYif8OPTJH2i3YcHiaS7ElIUJXkb4dnJTOOVCIB08EV0ONZgZHwtpsFCCwCFvRTouorcfz1SXs9a0vtjtau3CgBI3cl0yAGGuiazfipZAEsbB68QedFffR_QRl0ZBN_IfGIMC8ksxUw3R9J46tUET_doctLBvd7LFbDTfkECNoKCh-E5x-POLyjeWgscHe64WSRNkYgKaKTWP70Y9OdYg2CpCZseE55ovOqgNjTVCMlRhuQWO9zuBSLAU3NOfL-ms4n9AWrx75Wsg9gxkIGVm36HZ-yKO_wJDcrRRQqtYaS0noeqEdo3-Gmj4ldMgPOATkNXKLoFJ7P6FfnNYUiY7mPykn1_1tqlBEhVvSXrAteRNr6E_8s6lgFr4l2kDU8s8_XSgKu_wazGqw45WVMiO5Zgsh2SXh4VnnUE0LFubdThZsKCplGr_uJK2IFc0jiWlSid8rE2GiLU69Y0mVkwod2PQOfIfJRzeNkAA9raRbs5CkFO8XFVgLGjKWGIJw_8zKncKHZ-LgK0PVFJ2zMBMuN8fXofonS3v7Zm85gj16MGtfwIOVhvODG4BrOkZvI43TCM5pPRq1-5nqyJfJ6gpC0SWWwMrEF7YSZ64YIA5YmVlaquaB5Fam4p5O3EN8m83aQ4AcCBcRZAaimCtPIrIhK7SS394wkfQLFb8q_WUJe5RBHm3PoVsbjac3Vlu7rQTVByxSf9KdFNdtKTXJsMzLL0743ZMBmm4RA5UlQWE15AFeIyiSXP8B0TgFKe9J5g8W-eT8KWyqRw-x00_7lF0e-4tcB1B6CLOuk4kpkZk0WkucN0S1IzZRZsjXcOwmsoNDqFdpx7NrO08ZgmXqkSqwLCo99q0C6gpk2oX3-BBw9cDOgvFIpYE4A==')\n...     if str(y_true) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(y_true)}\n>>> responder.add_response(response)\n>>> assert str(y_true) == out, 'y_true is incorrect'\n",
         "failure_message": "y_true is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "y_true is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_5'\n>>> max_score = 3\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD-UVvxc6wECqC_U9taa6Art0EtaZg2i_WB0sp4FHCf3Ggyed8uUrljAkCPxg-AwYxN2jnqaPVgMh57F1OX1ftyjzR1SfhzBk5UAkxPaLIFHteLZY_7oK67GesWvX-jys-fhfKLktB_4ba54nXaVQP3K2xb60izc-42Y4VvddXu9Iggo5dy7VcJP8-6Ix_un8KqJo2J4CKYXFni2El-O9zrvvc1EcNYgvGdpzxFFeUHEHAP0AEqTp-Ow5D7T0x2iGcEPXtDUcmbgMG_t-HAQRr8ky9DNyuKx9k13pWT85O3jpLAtExhBYk2yXtzS9iU4pQEYGpYhdB2HQosUQcV5rXdgsC6pGcWlWhTab2uG32_Lt8-Y0jlb4VgALBAtxJGXuevGpJ7Pt1fzt7pjHikCVHcMbmkhLaWGzZq1uf6d6mbA-lxo1wGif7-ryFB4TTyze2HoxcGGgLI7vtuHgduBSd397OTTuS9PMMnR7oIXBZprj_NJrSmI79N4mMDlkWz-baZikhLw6LbThxinvd4HX6aQPVm3bPlV9M5Yc3lSqr2YQimUKqONnZGKxzcQx4TxfeRjdv8mS49Qey1KRU5zUlBS11NX-ScrqIFDAwFBsq6OpMSqd80rZquYE5E-IsHr0g4McffuDal20JZqXtP_kYMaT3Iv_KCa__9TKmpMHKJpQ44qhvzuBkqA59npHU05s5gbr5OpPwug1W_H7WTgjRYD-IaDU9cxxKWs9erfEkcCMh7peMvnBVwu2IY_W1u7ocNxXiMR2BJX6FbGO2P12t7D8vz3lyCJFHhkYggO06v9UF0L3-eX186gXNdegYnML3kVevZbOkRHFxvU2hoZ6dzLW8Z8SgaO9H1-Pac5Ima1Kh36EF1GH-93QGnSf6w2feXG9yByfSSbRharfHT6-79nYgl3EgGL0wo8imUaN8uwRhkxma8myGCAsNbkPKPiltTXfyv8yKEjc-qC5UivinYtFYYkhiDqIQvQDB4YURk0p4MxesM1rOgq6aML_jc7haRUcUes4ynGERvVt_Nc3bV03--BIzTZx4D2q3OMEUt25CyTU9oUr6r4C_JsrxhtK2d5U9qrLY6b-W-F-lBI3ZrRh_HcwHR9Hx7YTA7vRcXaOyYB-fUWjwXa2Gbxj1s9iEpzWf8lEisQk40FUhc2jSmtiZEn6MO3dO_YxJ3s9TE1Tmq9aK7gmb3zMbZn2gQyuHxzuvnUeJBi-DelNLvQXP7C3GYyMjA6TuajEzNY6VSVE7sKgQyw_vjE0QteWtkUpODlAbpT42M6laN3ahNeT7l2WE0D-wvjEHzflGOF7udat6QccodlHUge4DAJSS4vaTWs5J-aoSCmPNrYN65W3CIokMhxXS0VZ0n26ObdU384YVKdOTtUn796D7Mdk0ll0ImLLs_1RcihuZPkmEhE2rnWUINRBOLAyoQz6RrNGe-tC-uA3XNsxYbDQ9ReBPlU_R_BbkkgEzKtMV7juGtddtKDF-1lzhoahFX33CNMdWcuq189G87JsEED_tdmSloByFx3sEExB0uuj0--pnbH-CV1674xJ8x2WarCevNkOts1Aa0tDyE9v9v8NmX6cIKHsT8rkIhStCE1_Xknn2uMGlqNPp_5k30P5_mKeth6tti6uH-MMNO_qQ8V82Ki7X5u3HOmPgAa3_uJGD-JVvREQ8uNw8SVFpCmO-X207mkqYEFXO_Q=')\n...     if str(y_noisy) == out:\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(len(y_noisy))}\n>>> responder.add_response(response)\n>>> assert str(y_noisy) == out, 'y_noisy is incorrect'\n",
         "failure_message": "y_noisy is not implmemented correctly",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "y_noisy is implmemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_6'\n>>> max_score = 9\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD-VjEnvkOx1q5hIc6OiMyPE7iayGWAtZR_Kry0mvrQbCr0ffV9Lrck5j673YFnlWxRjo9qR44gKpYzUOzGhmCBpXKZ2Dec1hHWXhY4szHZZuirxAWmfMc66dj5dpA1bzjYFG')\n...     chars_to_remove = ['[', ']', '\\n']\n...     for char in chars_to_remove:\n...         out = out.replace(char, '')\n...     out = [float(x) for x in out.split(' ')]\n...     if np.allclose(popt, out):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([*popt])}\n>>> responder.add_response(response)\n>>> assert np.allclose(popt, out), 'popt is not returning the correct values'\n",
         "failure_message": "popt is not returning the correct values",
         "hidden": false,
         "locked": false,
         "points": 9,
         "success_message": "popt is returning the correct values"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_7'\n>>> max_score = 3\n>>> score = 0\n>>> with patch('builtins.print') as mock_print:\n...     out = get_string_from_encrypted_string(b'gAAAAABkD-WzDT72FrJF_4PrNsTIhnppKucv8pAjRnotXNrslY7YlSdDyqgiXabo32_bwcFXYkokXar7Vl-Bl1cN4lD70-PDCbfDPsxVDcGs25T4Z8IV-i6P7SAwaZ-k00NmVsJ4sF62ClW9ssomSd0jgYtbgy4J5sF9_KO-6s0ke6_Pfi1mrx8c90J5ZYsAwB9NKm45dZ-IWfjH955EkoxoPQcdqBQ16RG1J0k5DqGaP6hpRpR4mRANk50AFcgkX9PLqnKr3Z3AH1s_ugMEvza1GRlj1aVmaeF0JcHsVw1MxpZLLhPK0ikm8TcyX7cy6O8wi3xvjk5By8SFT96a0pqK5ObXGIuFAN6XlBH56yic8ttcRBODzaRiH_97wGvi8eUP0NNGOlMZFb_mPc7E9URWZCnJ0Krr57iOj5ALWDPqtMysnRGg4VCI9l6ZAFv0dP_HqbZT7U7TK_dFVAWNWv5MPeyg8rcGInJ2ygH1o1G8jRJRSbEcHQj3-ZU2K7DCFqc6xg2EO_31Dz6VLWnEBLVW2OUIth16vPCcjbmJgGuW0mgRulbogMNLFEXpGKJwi8LimBL_gZ0pee4vd8nZDKaRR8pSoLXsHyTHf-O8vXHzji4RiUF7VSReSrbpai1xoC7uyztjO1Vjce1bMf1pP7e3JNIzpJ7sfAlP0PPiERdG58Xe_2Qx_oWFMtQeDt-ViS4AWK76KlWgsiX0cFqWs3Dj_KMs1hmtywbEZtLkUjEUH6rclgw482Tp44fFQcUqBOOD92DJkGjmEr-FcVJtlu8R71hafSMBnOJ_cEUvZL-P5ljNUoUoM1I7REUK9hs-hiSYEyXbyCfv5dRSoXHOdNv0nDKoEcVWPYZPP3E74Qafmm47NHUNbcG3pMGXXMsOea7l5SnL_gfnYjNcvUIDEzZDXen2moiSP0P5EIeFTSItTdjSnM-TAMmDZlFSF3XtXD8vagpPb_-QdfPNOkkx1MQNjVXcKqDVPUwyuDkrqm0QFp2XrRW8Lwb7v5mENaD3HfZMlnpuBYAv9sXDtkb7Km30U9NgYExvScKEnBfbd61peROkRYXJiTA8uvx3xgWAeu47lCYNJ0jKomOQlJOVXH86TnPEjMKDQ9UUcFTJGcuQLaNfSPdSPqkf1gabg3e6VW4b--PSkhpss9OboUp1UOEo0KFnlj4Tl-zu8rwuWEUwlBUDYIyuKwWBYD_DpC62kBfCcuMuaM1xvbbMoedQLTm0OA0PIR_dP5nrW4IkGtnpbz43rqBMFCcGZ2un8KbCRT1mh8dB5nNdrtxl3dtBEB_nsl-M8gIqCruIfNHkoPx77SkXHT3zNnI66oYqgBpMCrTjShWB-xNtlRrKHqL0q9RpgPF9SJphcLBQ07eqV4s7TrJtfrhw41WuzLaCR7KYb_vsMj78KNrZmuaTDgGGu4lediwCYGOFA3I-jIxSj2jwYfDcrGKW9QUbDK5RTZ0_rEt6SwA5r7NpadXtv-RsGBycn-_vTNPQ_5PGIYGyY3GkQgVjiq0nBX1xI39PqmMKc0eyGKAH6pu2uhCw_FAe3GSSHzMke-zzIA==')\n...     chars_to_remove = ['[', ']', ' \\n']\n...     for char in chars_to_remove:\n...         out = out.replace(char, '')\n...     out = out.replace('  ', ' ')\n...     out = [float(x) for x in out.split(' ')]\n...     if np.allclose(y_fit, out):\n...         score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([*popt])}\n>>> responder.add_response(response)\n>>> assert np.allclose(y_fit, out), 'y_fit is returning incorrect values'\n",
         "failure_message": "y_fit is returning incorrect values",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "y_fit is returning correct values"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_8'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [plot_1.axes.get_xlabel() == 'x', plot_1.axes.get_ylabel() == 'y']\n>>> statements = ['xlabel is incorrect', 'ylabel is incorrect']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([plot_1.axes.get_xlabel(), plot_1.axes.get_ylabel()])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "The plot labels are incorrect.",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "The plot labels are correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_9'\n>>> max_score = 4\n>>> score = 0\n>>> conditions = [plot_1.get_label() == 'Noisy Data', plot_2[0].get_label() == 'Fitted Gaussian']\n>>> statements = ['Noisy Data', 'plot_1 is not labeled correctly', 'Fitted Gaussian', 'plot_2 is not labeled correctly']\n>>> for condition in conditions:\n...     if condition:\n...         score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([plot_1.get_label(), plot_2[0].get_label()])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "the plots are not labeled correctly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "the plots are labeled correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_10'\n>>> max_score = 3\n>>> score = 0\n>>> conditions = [plot_2[0].get_color() == (0.0, 0.5, 0.0, 1) or plot_2[0].get_color() == 'g' or plot_2[0].get_color() == 'green']\n>>> statements = ['gaussian fit is not the correct color']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([plot_2[0].get_color()])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "gaussian fit is not the correct color",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "gaussian fit is the correct color"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_11'\n>>> max_score = 3\n>>> score = 0\n>>> conditions = [plot_1.axes.get_legend() is not None]\n>>> statements = ['The legend is not correct on the plot']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str([plot_1.axes.get_legend() is not None])}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "The legend is not correct on the plot",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "The legend is correct on the plot"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_12'\n>>> max_score = 6\n>>> score = 0\n>>> conditions = [all(plot_2[0].get_xdata() == x_data), all(plot_2[0].get_ydata() == y_fit)]\n>>> statements = ['the x data for plot_2 is not correct', 'the y data for plot_2 is not correct']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "plot_2 does not have the correct values.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "plot_2 is correct."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score, get_string_from_encrypted_string\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q9_13'\n>>> max_score = 6\n>>> score = 0\n>>> conditions = [np.array_equal(plot_1.get_offsets()[:, 1], y_noisy), np.array_equal(plot_1.get_offsets()[:, 0], x_data)]\n>>> statements = ['the y data for plot_1 is not correct', 'the x data for plot_1 is not correct']\n>>> for condition in conditions:\n...     if condition:\n...         score += 3\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': str(conditions)}\n>>> responder.add_response(response)\n>>> for (condition, statement) in zip(conditions, statements):\n...     assert condition, statement\n",
         "failure_message": "plot_1 does not have the correct values.",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "plot_1 is correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d7d046052154998ca7dd3d9af52f7220fee50748c9a05b256540159ca8eb430c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
